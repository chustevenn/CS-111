NAME: Steven Chu
EMAIL: schu92620@gmail.com
ID: 905094800

The contents of this directory are as follows:

README: Descriptions of the contents of the directory as well as answers to the specified questions.

lab2_list.c: the source for a C program that compiles cleanly (with no errors or warnings), 
and implements the specified command line options (--threads, --iterations, --yield, --sync,
 --lists), drives one or more parallel threads that do operations on a shared linked list, 
and reports on the final list and performance.

lab2_list.gp: a script to generate the plots required by the spec.

test.sh: a script to run the tests specified by the spec, and input the resulting data into
lab2_list.csv.

lab2_list.csv: a CSV file containing the data generated by the specified test cases.

Makefile: support the specified options for building the executable, performing the tests,
generating the plots, and building the distribution tarball.

SortedList.c: the source for a C program that implements the insert, delete, lookup, 
and length methods for a sorted doubly linked list.

SortedList.h: a header file declaring the insert, delete, lookup, and length methods.

lab2b_1.png: Operations per second vs. Number of Threads

lab2b_2.png: Mutex threads vs. Avg wait time and lock time

lab2b_3.png: Unprotected Threads and Iterations that run without failure

lab2b_4.png: Mutex lock performance vs. Number of sublists

lab2b_5.png: Spin lock performance vs. Number of sublists

profile.out: a pprof output containing information on the performance of the spin lock
with various numbers of threads.

QUESTIONS:

2.3.1 - Cycles in the basic list implementation:
Where do you believe most of the cycles are spent in the 1 and 2-thread list tests ?
Why do you believe these to be the most expensive parts of the code?
Where do you believe most of the time/cycles are being spent in the high-thread spin-lock tests?
Where do you believe most of the time/cycles are being spent in the high-thread mutex tests?

Most of the cycles are probably spent doing the list operations in the 1 and 2-thread
list cases. These are the most expensive parts of the code in the 1 and 2-thread cases
because they are linear time operations with respect to the size of the list, whereas
the rest of the code does not involve such operations.

In the high-thread spin-lock tests, most of the time is likely spent performing spin cycle
instructions, due to the amount of time spent waiting for the lock by other threads. This
is because only one thread can be doing the list operation at a time, whil all other threads
will be executing spin instructions.

In the high-thread mutex lock tests, most of the time is likely spent performing context
switches or list operations. This is because each time a mutex lock cannot be acquired, the
OS must perform context switches to put the thread to sleep and wake the thread up.

2.3.2 - Execution Profiling:
Where (what lines of code) are consuming most of the cycles when the spin-lock version of the list exerciser is run with a large number of threads?
Why does this operation become so expensive with large numbers of threads?

The test and set line consumes the most cycles in the spin lock version of the list 
exerciser. This operation is very expensive with large numbers of threads because the amount
of contention increases with the number of threads. When large numbers of threads are
waiting on the spin lock, many times more instructions are being spent spinning than the
one thread that holds the lock performing list operations.

2.3.3 - Mutex Wait Time:
Look at the average time per operation (vs. # threads) and the average wait-for-mutex time (vs. #threads).
Why does the average lock-wait time rise so dramatically with the number of contending threads?
Why does the completion time per operation rise (less dramatically) with the number of contending threads?
How is it possible for the wait time per operation to go up faster (or higher) than the completion time per operation?

The average lock wait time increases dramatically because with more threads, each thread
needs to wait for that many threads to complete their list operations to receive the lock.
The cost of context switching more threads is also important. The wait time per operation 
can increase faster due to the fact that the time spent executing in other threads can count
toward the wait time in a particular thread.

2.3.4 - Performance of Partitioned Lists
Explain the change in performance of the synchronized methods as a function of the number of lists.
Should the throughput continue increasing as the number of lists is further increased? 
If not, explain why not.
It seems reasonable to suggest the throughput of an N-way partitioned list should be equivalent 
to the throughput of a single list with fewer (1/N) threads. 
Does this appear to be true in the above curves? If not, explain why not.

The performance increases with more lists, but it will not continue to increase past a 
certain point. This is because at some point, enough sublists will be created to eliminate
contention completely. After this point, no performance increase is possible simply by
creating more sublists.
No, it appears that an N-way partitioned list will perform better than a single list with
(1/N) fewer threads. This is due to the fact that a partitioned list will also decrease the
amount of time spent in the critical section, because list operations are linear time 
with respect to the size of the list.
